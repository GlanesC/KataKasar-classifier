{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84a4977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9229736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 2. Load Dataset\n",
    "# ==============================\n",
    "df = pd.read_excel(\n",
    "    \"D:\\File Kuliah D\\Semester 7\\Pemro Teks P\\Tugas Besar\\komentar_tiktok_jule_jefri.xlsx\"\n",
    ")\n",
    "\n",
    "assert isinstance(df, pd.DataFrame), \"df bukan DataFrame!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67af14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3. Tentukan Kolom Teks\n",
    "# ==============================\n",
    "TEXT_COLUMN = \"text\"\n",
    "\n",
    "if TEXT_COLUMN not in df.columns:\n",
    "    raise ValueError(f\"Kolom '{TEXT_COLUMN}' tidak ditemukan!\")\n",
    "\n",
    "df[TEXT_COLUMN] = df[TEXT_COLUMN].apply(lambda x: str(x))\n",
    "df = df[df[TEXT_COLUMN].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33850c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4. Fungsi Hapus Emoji\n",
    "# ==============================\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# ==============================\n",
    "# 5. Fungsi Preprocessing\n",
    "# ==============================\n",
    "def preprocessing(text):\n",
    "    text = str(text).lower()\n",
    "    text = remove_emojis(text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Normalisasi huruf berulang\n",
    "    normalized_tokens = [\n",
    "        re.sub(r'(.)\\1+', r'\\1', word) for word in tokens\n",
    "    ]\n",
    "\n",
    "    stopword_factory = StopWordRemoverFactory()\n",
    "    stopwords_id = set(stopword_factory.get_stop_words())\n",
    "\n",
    "    filtered_tokens = [\n",
    "        word for word in normalized_tokens\n",
    "        if word not in stopwords_id and len(word) > 3\n",
    "    ]\n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f100372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 6. Lexicon Kata Kasar\n",
    "# ==============================\n",
    "lexicon_kasar = list(set([\n",
    "    \"anjing\",\"bangsat\",\"goblok\",\"tolol\",\"kontol\",\n",
    "    \"memek\",\"ngentot\",\"asu\",\"bego\",\"tai\",\n",
    "    \"kampret\",\"bacot\",\"sialan\",\"brengsek\",\n",
    "    \"anj\",\"anjg\",\"anjir\",\"njir\",\"jir\",\n",
    "    \"cok\",\"jancok\",\"cuuk\",\n",
    "    \"fefek\",\"mmk\",\"kontl\",\"ngntt\",\n",
    "    \"redup\",\"gemeter\",\"gemetar\"\n",
    "]))\n",
    "\n",
    "# ==============================\n",
    "# 7. Fungsi Deteksi Kata Kasar\n",
    "# ==============================\n",
    "def contains_profanity(tokens):\n",
    "    for word in tokens:\n",
    "        if word in lexicon_kasar:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212ff50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 8. Proses Preprocessing\n",
    "# ==============================\n",
    "df[\"tokens\"] = df[TEXT_COLUMN].apply(preprocessing)\n",
    "df[\"clean_text\"] = df[\"tokens\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# ==============================\n",
    "# 9. Proses Pelabelan\n",
    "# ==============================\n",
    "df[\"label\"] = df[\"tokens\"].apply(\n",
    "    lambda x: \"kasar\" if contains_profanity(x) else \"non_kasar\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30facbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jefri penasaran apa gimana sihðŸ˜­ðŸ˜­</td>\n",
       "      <td>[jefri, penasaran, gimana]</td>\n",
       "      <td>jefri penasaran gimana</td>\n",
       "      <td>non_kasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.12 dilalui</td>\n",
       "      <td>[dilalui]</td>\n",
       "      <td>dilalui</td>\n",
       "      <td>non_kasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fefek jule sebenernya parian apa sihðŸ˜­</td>\n",
       "      <td>[fefek, jule, sebenernya, parian]</td>\n",
       "      <td>fefek jule sebenernya parian</td>\n",
       "      <td>kasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fefeknya laris anjirðŸ˜­ðŸ˜­ðŸ˜­</td>\n",
       "      <td>[fefeknya, laris, anjir]</td>\n",
       "      <td>fefeknya laris anjir</td>\n",
       "      <td>kasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inara diselip jule terusðŸ˜­</td>\n",
       "      <td>[inara, diselip, jule, terus]</td>\n",
       "      <td>inara diselip jule terus</td>\n",
       "      <td>non_kasar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  \\\n",
       "0    Jefri penasaran apa gimana sihðŸ˜­ðŸ˜­   \n",
       "1                             12.12 dilalui   \n",
       "2  fefek jule sebenernya parian apa sihðŸ˜­   \n",
       "3          fefeknya laris anjirðŸ˜­ðŸ˜­ðŸ˜­   \n",
       "4              inara diselip jule terusðŸ˜­   \n",
       "\n",
       "                              tokens                    clean_text      label  \n",
       "0         [jefri, penasaran, gimana]        jefri penasaran gimana  non_kasar  \n",
       "1                          [dilalui]                       dilalui  non_kasar  \n",
       "2  [fefek, jule, sebenernya, parian]  fefek jule sebenernya parian      kasar  \n",
       "3           [fefeknya, laris, anjir]          fefeknya laris anjir      kasar  \n",
       "4      [inara, diselip, jule, terus]      inara diselip jule terus  non_kasar  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d29d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['clean_text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a9a5c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa605701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35ca5b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3496\\3006716147.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01589704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4513 entries, 0 to 5167\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   clean_text  4513 non-null   object\n",
      " 1   label       4513 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 105.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c9bb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 10. Simpan Dataset Hasil\n",
    "# ==============================\n",
    "output_file = \"komentar_tiktok_labeled.xlsx\"\n",
    "\n",
    "df[[\"clean_text\", \"label\"]].to_excel(\n",
    "    output_file,\n",
    "    index=False,\n",
    "    engine=\"openpyxl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "321d278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "label\n",
      "non_kasar    3924\n",
      "kasar         589\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset berhasil disimpan sebagai: komentar_tiktok_labeled.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 11. Evaluasi Awal\n",
    "# ==============================\n",
    "print(\"Distribusi label:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "print(f\"\\nDataset berhasil disimpan sebagai: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
